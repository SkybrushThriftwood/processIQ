# API Keys
OPENAI_API_KEY=your-openai-key-here
ANTHROPIC_API_KEY=your-anthropic-key-here
LANGSMITH_API_KEY=your-langsmith-key-here

# Observability
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com  # Use https://eu.api.smith.langchain.com for EU
LANGCHAIN_PROJECT=processiq
LOG_LEVEL=INFO

# Global LLM Settings (defaults for all tasks)
# LLM_PROVIDER options: anthropic, openai, or ollama
LLM_PROVIDER=openai
# LLM_MODEL: Empty = use provider default (gpt-4o for openai, claude-sonnet-4 for anthropic)
LLM_MODEL=
LLM_TEMPERATURE=0.0
LLM_EXPLANATIONS_ENABLED=true

# Per-Task LLM Overrides (JSON format)
# Each task can use a different model. Unset fields inherit from global settings.
# Tasks: extraction, clarification, explanation, summary, framework
#
# Examples:
# LLM_TASK_EXTRACTION='{"model": "gpt-4o-mini"}'  # Fast model for data extraction
# LLM_TASK_SUMMARY='{"provider": "anthropic", "model": "claude-sonnet-4-20250514"}'  # Better summaries
# LLM_TASK_FRAMEWORK='{"provider": "anthropic", "model": "claude-sonnet-4-20250514", "temperature": 0.3}'  # Creative analysis

# Analysis Settings
CONFIDENCE_THRESHOLD=0.6  # Minimum confidence to proceed without asking for more data
