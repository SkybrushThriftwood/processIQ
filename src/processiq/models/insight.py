"""LLM-generated insight models for ProcessIQ.

These models represent the OUTPUT of LLM analysis, where the LLM
makes judgments about what's a problem and what to recommend.

Key principle: The LLM fills these models, algorithms verify the math.
"""

from typing import Literal

from pydantic import BaseModel, Field


class Issue(BaseModel):
    """An issue identified by the LLM during analysis.

    The LLM decides what constitutes an issue based on context,
    not just which step has max(time).
    """

    title: str = Field(
        ...,
        min_length=1,
        max_length=100,
        description="Short title for the issue (e.g., 'Review Consolidation Opportunity')",
    )
    description: str = Field(
        ...,
        min_length=1,
        description="Natural language explanation of the issue",
    )
    affected_steps: list[str] = Field(
        default_factory=list,
        description="Step names this issue relates to",
    )
    severity: Literal["high", "medium", "low"] = Field(
        ...,
        description="How significant is this issue",
    )
    root_cause_hypothesis: str = Field(
        default="",
        description="Why this issue might exist (hypothesis, not certainty)",
    )
    evidence: list[str] = Field(
        default_factory=list,
        description="Data points supporting this issue (from metrics)",
    )


class Recommendation(BaseModel):
    """A recommendation generated by the LLM.

    Tied to specific issues and includes trade-offs.
    """

    title: str = Field(
        ...,
        min_length=1,
        max_length=100,
        description="Short action title (e.g., 'Combine manager reviews')",
    )
    addresses_issue: str = Field(
        ...,
        description="Which Issue.title this addresses",
    )
    description: str = Field(
        ...,
        description="What to do, explained clearly",
    )
    expected_benefit: str = Field(
        ...,
        description="Qualitative benefit (e.g., '~1 hour saved per project')",
    )
    risks: list[str] = Field(
        default_factory=list,
        description="Trade-offs and potential downsides",
    )
    feasibility: Literal["easy", "moderate", "complex"] = Field(
        ...,
        description="How hard is this to implement",
    )
    affected_steps: list[str] = Field(
        default_factory=list,
        description="Which steps would change if implemented",
    )
    prerequisites: list[str] = Field(
        default_factory=list,
        description="What needs to be true for this to work",
    )

    # Progressive disclosure fields (Layer 2 & 3)
    plain_explanation: str = Field(
        default="",
        description="What this means in simple, non-technical terms. "
        "Include realistic cost context for the business size.",
    )
    concrete_next_steps: list[str] = Field(
        default_factory=list,
        description="2-4 specific actions to start implementing this, "
        "ordered chronologically. First step should be doable this week.",
    )


class NotAProblem(BaseModel):
    """A step that looks problematic but isn't.

    The LLM explicitly identifies steps that might appear
    to be bottlenecks but are actually core value.
    """

    step_name: str = Field(..., description="The step name")
    why_not_a_problem: str = Field(
        ...,
        description="Why this step isn't waste to eliminate",
    )
    appears_problematic_because: str = Field(
        default="",
        description="Why someone might mistakenly flag this",
    )


class AnalysisInsight(BaseModel):
    """Complete LLM-generated analysis output.

    This replaces the algorithm-centric AnalysisResult with
    LLM-generated insights that provide real value.
    """

    # Summary (what the LLM understood)
    process_summary: str = Field(
        ...,
        description="1-2 sentence summary of the process (e.g., '13-step project workflow, ~14 hours')",
    )

    # Patterns (what stands out)
    patterns: list[str] = Field(
        default_factory=list,
        description="Observed patterns as strings (e.g., '4 approval steps', '3 client handoffs')",
    )

    # Issues (what's likely causing problems)
    issues: list[Issue] = Field(
        default_factory=list,
        description="Problems identified, with root cause hypotheses",
    )

    # Recommendations (what to do about it)
    recommendations: list[Recommendation] = Field(
        default_factory=list,
        description="Specific, contextual suggestions with trade-offs",
    )

    # Not problems (what looks bad but isn't)
    not_problems: list[NotAProblem] = Field(
        default_factory=list,
        description="Steps that look slow but are core work, not waste",
    )

    # Follow-up questions (what would help)
    follow_up_questions: list[str] = Field(
        default_factory=list,
        description="Questions that would help refine the analysis",
    )

    # Confidence and caveats
    confidence_notes: str = Field(
        default="",
        description="Caveats about the analysis (e.g., 'Limited by missing error rates')",
    )

    # Raw thinking (optional, for debugging)
    reasoning: str = Field(
        default="",
        description="The LLM's reasoning process (optional)",
    )


class AnalysisRequest(BaseModel):
    """Request structure for LLM analysis.

    Contains the pre-calculated metrics and context for the LLM.
    """

    metrics_text: str = Field(
        ..., description="Formatted metrics from format_metrics_for_llm()"
    )
    industry: str | None = Field(default=None, description="Industry context if known")
    constraints_summary: str | None = Field(
        default=None, description="Active constraints"
    )
    user_concerns: str | None = Field(
        default=None, description="What the user mentioned as problems"
    )
